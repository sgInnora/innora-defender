#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Malware Analysis and Automated Decryption Module

This module provides a comprehensive framework for detailed malware analysis,
integration with automated workflow, and decryption capabilities.

It integrates static analysis, dynamic behavior analysis, network analysis, 
and leverages the decryption tools to attempt recovery of encrypted files.
"""

import os
import sys
import json
import logging
import argparse
import hashlib
import tempfile
import datetime
import time
import threading
import subprocess
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Set, Optional, Any, Union

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import project components
from decryption_tools.ransomware_recovery import RansomwareRecovery
from decryption_tools.external.encryption_analyzer import EncryptionAnalyzer
from decryption_tools.network_forensics.network_based_recovery import NetworkKeyExtractor, NetworkBasedRecovery

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('AdvancedMalwareAnalysis')


class AdvancedMalwareAnalyzer:
    """
    Advanced malware analysis and decryption framework that integrates multiple
    analysis techniques and automated workflow.
    """
    
    def __init__(self, sample_path, output_dir=None, work_dir=None, verbose=False):
        """
        Initialize the advanced malware analyzer
        
        Args:
            sample_path: Path to the malware sample
            output_dir: Output directory for results
            work_dir: Working directory for temporary files
            verbose: Enable verbose logging
        """
        self.sample_path = os.path.abspath(sample_path)
        self.sample_name = os.path.basename(sample_path)
        self.verbose = verbose
        
        # Set up logging
        if verbose:
            logging.getLogger().setLevel(logging.DEBUG)
        
        # Set up directories
        if work_dir:
            self.work_dir = os.path.abspath(work_dir)
        else:
            self.work_dir = tempfile.mkdtemp(prefix='adv_malware_analysis_')
            
        if output_dir:
            self.output_dir = os.path.abspath(output_dir)
        else:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            self.output_dir = os.path.join(os.path.dirname(self.sample_path), 
                                         f"adv_analysis_{os.path.splitext(self.sample_name)[0]}_{timestamp}")
        
        # Create necessary directories
        os.makedirs(self.work_dir, exist_ok=True)
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'static'), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'dynamic'), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'network'), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'memory'), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'decryption'), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'reports'), exist_ok=True)
        
        # Set up log file
        log_file = os.path.join(self.output_dir, 'analysis.log')
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        logging.getLogger().addHandler(file_handler)
        
        # Initialize components
        self.recovery = RansomwareRecovery(self.work_dir)
        self.encryption_analyzer = EncryptionAnalyzer()
        
        # Copy sample to work directory
        self.sample_copy = os.path.join(self.work_dir, self.sample_name)
        
        # Analysis results
        self.results = {
            'sample': {
                'path': self.sample_path,
                'name': self.sample_name,
                'size': 0,
                'hashes': {}
            },
            'timestamp': datetime.datetime.now().isoformat(),
            'static_analysis': {},
            'dynamic_analysis': {},
            'network_analysis': {},
            'memory_analysis': {},
            'decryption_attempts': [],
            'identified_family': None,
            'family_confidence': 0.0,
            'decryption_successful': False
        }
        
    def compute_hashes(self):
        """Compute cryptographic hashes of the sample"""
        logger.info("Computing cryptographic hashes...")
        
        try:
            with open(self.sample_path, 'rb') as f:
                data = f.read()
                
            self.results['sample']['size'] = len(data)
            
            # Compute hashes
            md5 = hashlib.md5(data).hexdigest()
            sha1 = hashlib.sha1(data).hexdigest()
            sha256 = hashlib.sha256(data).hexdigest()
            
            self.results['sample']['hashes'] = {
                'md5': md5,
                'sha1': sha1,
                'sha256': sha256
            }
            
            logger.info(f"MD5: {md5}")
            logger.info(f"SHA1: {sha1}")
            logger.info(f"SHA256: {sha256}")
            
            return True
        except Exception as e:
            logger.error(f"Error computing hashes: {e}")
            return False
            
    def prepare_sample(self):
        """Prepare the sample for analysis"""
        logger.info("Preparing sample for analysis...")
        
        try:
            # Copy sample to work directory
            shutil.copy2(self.sample_path, self.sample_copy)
            
            # Set permissions
            os.chmod(self.sample_copy, 0o600)
            
            logger.info(f"Sample copied to: {self.sample_copy}")
            return True
        except Exception as e:
            logger.error(f"Error preparing sample: {e}")
            return False
    
    def check_file_type(self):
        """Determine the type of the sample file"""
        logger.info("Checking file type...")
        
        try:
            # Use file command to determine type
            proc = subprocess.run(['file', '-b', self.sample_copy], capture_output=True, check=False)
            output = proc.stdout.decode('utf-8', errors='ignore').strip()
            self.results['sample']['file_type'] = output
            
            logger.info(f"File type: {output}")
            return output
        except Exception as e:
            logger.error(f"Error checking file type: {e}")
            self.results['sample']['file_type'] = "Unknown"
            return "Unknown"
    
    def perform_static_analysis(self):
        """Perform comprehensive static analysis of the sample"""
        logger.info("Performing static analysis...")
        
        static_results = {}
        
        # 1. Check file type
        file_type = self.check_file_type()
        static_results['file_type'] = file_type
        
        # 2. Extract strings
        try:
            logger.info("Extracting strings...")
            strings_output = os.path.join(self.output_dir, 'static', 'strings.txt')
            
            # Extract ASCII strings
            try:
                ascii_proc = subprocess.run(['strings', '-a', '-n', '8', self.sample_copy], 
                                          capture_output=True, check=False)
                ascii_output = ascii_proc.stdout.decode('utf-8', errors='ignore')
            except Exception as e:
                logger.warning(f"Error extracting ASCII strings: {e}")
                ascii_output = ""
            
            # Extract Unicode strings
            try:
                unicode_proc = subprocess.run(['strings', '-a', '-n', '8', '-e', 'l', self.sample_copy], 
                                            capture_output=True, check=False)
                unicode_output = unicode_proc.stdout.decode('utf-8', errors='ignore')
            except Exception as e:
                logger.warning(f"Error extracting Unicode strings: {e}")
                unicode_output = ""
            
            # Combine and write to file
            with open(strings_output, 'w') as f:
                f.write("=== ASCII STRINGS ===\n")
                f.write(ascii_output)
                f.write("\n\n=== UNICODE STRINGS ===\n")
                f.write(unicode_output)
            
            static_results['strings_file'] = strings_output
            logger.info(f"Strings saved to: {strings_output}")
            
            # 3. Analyze strings for indicators
            logger.info("Analyzing strings for indicators...")
            
            # Keywords categorized by type
            indicators = {
                'ransomware': [
                    'ransom', 'encrypt', 'decrypt', 'bitcoin', 'btc', 'wallet', 'payment', 
                    'victim', 'restore', 'recovery', '.onion', 'tor', 'locker', 'locked', 
                    'unlock', 'key', 'readme', 'read_me', 'help_decrypt', 'how_to_decrypt',
                    'pay', 'deadline', 'timer', 'time', 'restore_files'
                ],
                'encryption': [
                    'aes', 'rsa', 'chacha', 'salsa', 'blowfish', 'twofish', 'rijndael', 
                    'public_key', 'private_key', 'encrypt', 'decrypt', 'cipher', 'cryptography'
                ],
                'network': [
                    'http://', 'https://', '.onion', 'url', 'server', 'connect', 'ip', 
                    'socket', 'dns', 'domain', 'download', 'upload', 'exfiltrat', 'botnet',
                    'command', 'control', 'proxy', 'vpn', 'tor'
                ],
                'persistence': [
                    'registry', 'startup', 'boot', 'autorun', 'autostart', 'regedit', 
                    'service', 'scheduled', 'task', 'persistence', 'survive', 'restart'
                ],
                'evasion': [
                    'antivirus', 'anti-virus', 'sandbox', 'virtual', 'vm', 'debug', 
                    'detect', 'vmware', 'virtualbox', 'qemu', 'bochs', 'sleep', 'delay'
                ],
                'data_theft': [
                    'password', 'credentials', 'cookie', 'database', 'dump', 'exfil', 
                    'keylog', 'screenshot', 'webcam', 'record', 'steal', 'sensitive'
                ]
            }
            
            # Search for indicators in strings
            found_indicators = {}
            combined_strings = ascii_output + unicode_output
            
            for category, keywords in indicators.items():
                matches = {}
                for keyword in keywords:
                    count = combined_strings.lower().count(keyword.lower())
                    if count > 0:
                        matches[keyword] = count
                
                if matches:
                    found_indicators[category] = matches
            
            static_results['indicators'] = found_indicators
            
            # Calculate category scores based on indicators
            category_scores = {}
            for category, matches in found_indicators.items():
                total_matches = sum(matches.values())
                unique_keywords = len(matches)
                # Score formula: (0.7 * unique_keywords / total_possible) + (0.3 * total_matches / 100)
                # Capped at 1.0
                score = min(1.0, (0.7 * unique_keywords / len(indicators[category])) + 
                           (0.3 * min(1.0, total_matches / 100)))
                category_scores[category] = round(score, 2)
            
            static_results['category_scores'] = category_scores
            
        except Exception as e:
            logger.error(f"Error extracting strings: {e}")
        
        # 4. Analyze PE file (if applicable)
        if "PE32" in file_type or "PE32+" in file_type:
            try:
                logger.info("Analyzing PE file structure...")
                
                # Run PE analysis using pefile if available
                try:
                    import pefile
                    pe = pefile.PE(self.sample_copy)
                    
                    # Extract imports
                    imports = {}
                    for entry in pe.DIRECTORY_ENTRY_IMPORT:
                        dll_name = entry.dll.decode('utf-8')
                        imports[dll_name] = []
                        for imp in entry.imports:
                            if imp.name:
                                imports[dll_name].append(imp.name.decode('utf-8'))
                            else:
                                imports[dll_name].append(f"ord({imp.ordinal})")
                    
                    static_results['pe_imports'] = imports
                    
                    # Extract sections
                    sections = []
                    for section in pe.sections:
                        section_name = section.Name.decode('utf-8').strip('\x00')
                        sections.append({
                            'name': section_name,
                            'virtual_address': hex(section.VirtualAddress),
                            'virtual_size': hex(section.Misc_VirtualSize),
                            'raw_size': hex(section.SizeOfRawData),
                            'entropy': section.get_entropy()
                        })
                    
                    static_results['pe_sections'] = sections
                    
                    # Analyze section entropy for signs of encryption/packing
                    high_entropy_sections = [s for s in sections if s['entropy'] > 7.0]
                    if high_entropy_sections:
                        static_results['high_entropy_sections'] = high_entropy_sections
                        logger.info(f"Detected {len(high_entropy_sections)} high-entropy PE sections, possible encryption or packing")
                    
                    # Extract resources
                    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):
                        resources = []
                        for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:
                            if hasattr(resource_type, 'directory'):
                                for resource_id in resource_type.directory.entries:
                                    if hasattr(resource_id, 'directory'):
                                        for resource_lang in resource_id.directory.entries:
                                            data_rva = resource_lang.data.struct.OffsetToData
                                            size = resource_lang.data.struct.Size
                                            resources.append({
                                                'type': resource_type.id,
                                                'id': resource_id.id,
                                                'lang': resource_lang.id,
                                                'size': size
                                            })
                        
                        static_results['pe_resources'] = resources
                    
                    # Check for TLS callbacks (common persistence/anti-debug technique)
                    if hasattr(pe, 'DIRECTORY_ENTRY_TLS'):
                        tls_callbacks = []
                        callback_array_rva = pe.DIRECTORY_ENTRY_TLS.struct.AddressOfCallBacks
                        if callback_array_rva:
                            callback_array_offset = pe.get_offset_from_rva(callback_array_rva)
                            while True:
                                callback = pe.get_dword_at_rva(callback_array_rva)
                                if callback == 0:
                                    break
                                tls_callbacks.append(hex(callback))
                                callback_array_rva += 4
                        
                        if tls_callbacks:
                            static_results['pe_tls_callbacks'] = tls_callbacks
                            logger.info(f"Detected {len(tls_callbacks)} TLS callbacks, potential anti-debugging technique")
                    
                    pe.close()
                    
                except ImportError:
                    logger.warning("pefile module not available, skipping detailed PE analysis")
                    # Fallback to basic PE analysis using other tools
                    
                # Run additional analysis with VirusTotal Intelligence API if available
                # (Commented out as it requires VT API key)
                # self._check_virustotal(self.results['sample']['hashes']['sha256'])
                
            except Exception as e:
                logger.error(f"Error analyzing PE file: {e}")
        
        # 5. Analyze encryption capabilities
        try:
            logger.info("Analyzing for encryption capabilities...")
            
            # Use EncryptionAnalyzer from the ransomware_recovery module
            encryption_results = self.encryption_analyzer.analyze_file(self.sample_copy)
            
            # Store the full analysis results
            static_results['encryption_analysis'] = encryption_results
            
            # Extract key information
            if 'potential_family' in encryption_results and encryption_results['potential_family']:
                family = encryption_results['potential_family']
                self.results['identified_family'] = family
                if 'family_confidence' in encryption_results:
                    self.results['family_confidence'] = encryption_results['family_confidence']
                logger.info(f"Detected potential ransomware family: {family} (Confidence: {self.results['family_confidence']})")
        
        except Exception as e:
            logger.error(f"Error analyzing encryption capabilities: {e}")
        
        # 6. Analyze code patterns with YARA if available
        try:
            import yara
            
            logger.info("Scanning with YARA rules...")
            
            # Path to rules directory
            rules_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 
                                   "threat_intel", "rules")
            
            if os.path.exists(rules_dir):
                # Compile YARA rules
                rules_files = {}
                for root, _, files in os.walk(rules_dir):
                    for filename in files:
                        if filename.endswith('.yar') or filename.endswith('.yara'):
                            rule_path = os.path.join(root, filename)
                            try:
                                rules_files[filename] = rule_path
                            except Exception as e:
                                logger.debug(f"Error compiling rule {filename}: {e}")
                
                # Scan with each rule file separately (to identify which rule file matched)
                yara_matches = {}
                for rule_name, rule_path in rules_files.items():
                    try:
                        rule = yara.compile(rule_path)
                        matches = rule.match(self.sample_copy)
                        if matches:
                            yara_matches[rule_name] = [match.rule for match in matches]
                    except Exception as e:
                        logger.debug(f"Error scanning with {rule_name}: {e}")
                
                if yara_matches:
                    static_results['yara_matches'] = yara_matches
                    logger.info(f"Found {sum(len(m) for m in yara_matches.values())} YARA matches")
        
        except ImportError:
            logger.warning("YARA module not available, skipping YARA analysis")
        
        # Save static analysis results
        self.results['static_analysis'] = static_results
        
        # Write report to file
        static_report_path = os.path.join(self.output_dir, 'static', 'static_analysis.json')
        with open(static_report_path, 'w') as f:
            json.dump(static_results, f, indent=2)
        
        logger.info(f"Static analysis report saved to: {static_report_path}")
        return True
    
    def extract_network_indicators(self):
        """Extract network indicators from the sample"""
        logger.info("Extracting network indicators...")
        
        network_results = {}
        
        # Extract common network indicators from strings
        try:
            with open(os.path.join(self.output_dir, 'static', 'strings.txt'), 'r') as f:
                strings_data = f.read()
            
            # Extract URLs
            url_pattern = r'https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+(?:/[-\w%!$&\'()*+,;=:@/~]+)*(?:\?[-\w%!$&\'()*+,;=:@/~]*)?'
            urls = set(re.findall(url_pattern, strings_data))
            
            # Extract IP addresses
            ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
            ips = set(re.findall(ip_pattern, strings_data))
            # Filter out invalid IPs
            valid_ips = set()
            for ip in ips:
                try:
                    parts = [int(p) for p in ip.split('.')]
                    if all(0 <= p <= 255 for p in parts):
                        valid_ips.add(ip)
                except:
                    pass
            
            # Extract domains
            domain_pattern = r'\b(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}\b'
            domains = set(re.findall(domain_pattern, strings_data))
            # Filter out common false positives
            filtered_domains = set()
            common_false_positives = {'microsoft.com', 'google.com', 'example.com', 'windows.com'}
            for domain in domains:
                if domain.lower() not in common_false_positives:
                    filtered_domains.add(domain)
            
            # Store network indicators
            network_indicators = {
                'urls': list(urls),
                'ip_addresses': list(valid_ips),
                'domains': list(filtered_domains)
            }
            
            network_results['network_indicators'] = network_indicators
            logger.info(f"Extracted {len(urls)} URLs, {len(valid_ips)} IP addresses, and {len(filtered_domains)} domains")
            
            # Save to file
            indicators_path = os.path.join(self.output_dir, 'network', 'network_indicators.json')
            with open(indicators_path, 'w') as f:
                json.dump(network_indicators, f, indent=2)
            
            logger.info(f"Network indicators saved to: {indicators_path}")
        
        except Exception as e:
            logger.error(f"Error extracting network indicators: {e}")
        
        # Check for C2 patterns using NetworkKeyExtractor
        try:
            logger.info("Analyzing for C2 communication patterns...")
            
            # Create a dummy PCAP file (for analysis only)
            dummy_pcap = os.path.join(self.work_dir, 'dummy.pcap')
            with open(dummy_pcap, 'wb') as f:
                f.write(b'\x00' * 24)  # Minimal PCAP header
            
            # Initialize extractor
            extractor = NetworkKeyExtractor(dummy_pcap)
            
            # Check for C2 patterns in the binary
            with open(self.sample_copy, 'rb') as f:
                binary_data = f.read()
            
            c2_matches = []
            for family, patterns in extractor.c2_patterns.items():
                family_matches = []
                for pattern, confidence in patterns.items():
                    if pattern in binary_data:
                        family_matches.append({
                            'pattern': pattern.decode('utf-8', errors='ignore'),
                            'confidence': confidence
                        })
                
                if family_matches:
                    c2_matches.append({
                        'family': family,
                        'pattern_matches': family_matches,
                        'match_count': len(family_matches),
                        'confidence': sum(m['confidence'] for m in family_matches) / len(family_matches)
                    })
            
            if c2_matches:
                network_results['c2_pattern_matches'] = c2_matches
                
                # Update family identification if C2 patterns provide higher confidence
                best_match = max(c2_matches, key=lambda x: x['confidence'])
                if best_match['confidence'] > self.results['family_confidence']:
                    self.results['identified_family'] = best_match['family']
                    self.results['family_confidence'] = best_match['confidence']
                    logger.info(f"Updated family identification based on C2 patterns: {best_match['family']} (Confidence: {best_match['confidence']})")
            
        except Exception as e:
            logger.error(f"Error analyzing C2 patterns: {e}")
        
        # Save network analysis results
        self.results['network_analysis'] = network_results
        
        # Write report to file
        network_report_path = os.path.join(self.output_dir, 'network', 'network_analysis.json')
        with open(network_report_path, 'w') as f:
            json.dump(network_results, f, indent=2)
        
        logger.info(f"Network analysis report saved to: {network_report_path}")
        return True
    
    def prepare_dynamic_analysis(self):
        """Prepare environment for dynamic analysis"""
        logger.info("Preparing dynamic analysis environment...")
        
        dynamic_results = {}
        
        # Create test directory with dummy files
        test_dir = os.path.join(self.work_dir, 'test_files')
        os.makedirs(test_dir, exist_ok=True)
        
        # Create various file types for testing encryption
        file_types = [
            {'ext': '.txt', 'content': 'This is a test text file for ransomware analysis.'},
            {'ext': '.doc', 'content': 'TEST DOCUMENT FILE'},
            {'ext': '.xls', 'content': 'TEST SPREADSHEET FILE'},
            {'ext': '.pdf', 'content': '%PDF-1.5\nTest PDF file for ransomware analysis\n%%EOF'},
            {'ext': '.jpg', 'content': 'TESTJPGFILE'}
        ]
        
        created_files = []
        for i in range(1, 11):
            for file_type in file_types:
                file_name = f"test_{i}{file_type['ext']}"
                file_path = os.path.join(test_dir, file_name)
                
                with open(file_path, 'w') as f:
                    f.write(file_type['content'])
                
                created_files.append(file_path)
        
        # Create subdirectory with important files
        important_dir = os.path.join(test_dir, 'important')
        os.makedirs(important_dir, exist_ok=True)
        
        for i in range(1, 6):
            file_path = os.path.join(important_dir, f"important_{i}.txt")
            with open(file_path, 'w') as f:
                f.write(f"This is an important file #{i} for ransomware analysis")
            created_files.append(file_path)
        
        dynamic_results['test_directory'] = test_dir
        dynamic_results['test_files'] = created_files
        
        # Prepare monitoring scripts
        monitor_script_src = os.path.join(os.path.dirname(os.path.abspath(__file__)), 
                                       "sandboxes", "isolation", "monitor_scripts", "monitor_ransomware.sh")
        
        if os.path.exists(monitor_script_src):
            monitor_script_dst = os.path.join(self.work_dir, "monitor_ransomware.sh")
            shutil.copy2(monitor_script_src, monitor_script_dst)
            os.chmod(monitor_script_dst, 0o755)
            
            dynamic_results['monitor_script'] = monitor_script_dst
            
            # Create example command
            monitor_cmd = f"{monitor_script_dst} {self.sample_copy} {test_dir}"
            dynamic_results['monitor_command'] = monitor_cmd
            
            logger.info(f"Monitoring script prepared: {monitor_script_dst}")
        
        # Check for docker availability
        try:
            subprocess.check_output(['docker', '--version'])
            dynamic_results['docker_available'] = True
            
            # Build docker command for sandboxed execution
            docker_cmd = (
                f"docker run --rm -it --network none "
                f"-v {self.work_dir}:/analysis/workspace "
                f"-v {self.output_dir}/dynamic:/analysis/output "
                f"ransomware-analysis-sandbox "
                f"/analysis/workspace/{self.sample_name}"
            )
            
            dynamic_results['docker_command'] = docker_cmd
            logger.info("Docker is available for sandboxed execution")
            
        except Exception:
            dynamic_results['docker_available'] = False
            logger.warning("Docker is not available")
        
        # Save dynamic analysis preparation results
        self.results['dynamic_analysis'] = dynamic_results
        
        # Write report to file
        dynamic_report_path = os.path.join(self.output_dir, 'dynamic', 'dynamic_analysis_setup.json')
        with open(dynamic_report_path, 'w') as f:
            json.dump(dynamic_results, f, indent=2)
        
        logger.info(f"Dynamic analysis setup report saved to: {dynamic_report_path}")
        return True
    
    def attempt_decryption(self, files_to_decrypt=None):
        """
        Attempt to decrypt files using available tools and extracted keys
        
        Args:
            files_to_decrypt: Optional list of files to decrypt (uses test files by default)
        """
        logger.info("Attempting decryption...")
        
        decryption_results = []
        
        # Get the files to decrypt
        if not files_to_decrypt:
            # Use test files if available
            if 'dynamic_analysis' in self.results and 'test_files' in self.results['dynamic_analysis']:
                files_to_decrypt = self.results['dynamic_analysis']['test_files']
            else:
                logger.warning("No files specified for decryption")
                return []
        
        # Create output directory for decrypted files
        decrypted_dir = os.path.join(self.output_dir, 'decryption', 'decrypted_files')
        os.makedirs(decrypted_dir, exist_ok=True)
        
        # Attempt decryption based on identified family
        if self.results['identified_family']:
            family = self.results['identified_family']
            logger.info(f"Attempting decryption for identified family: {family}")
            
            # Find available decryption tools for this family
            available_tools = self.recovery.list_tools(family)
            
            if available_tools:
                logger.info(f"Found {len(available_tools)} decryption tools for {family}")
                
                for tool in available_tools:
                    tool_id = tool.get('id')
                    logger.info(f"Attempting decryption with tool: {tool_id}")
                    
                    # Try to decrypt each file
                    for file_path in files_to_decrypt:
                        if os.path.exists(file_path):
                            file_name = os.path.basename(file_path)
                            output_file = os.path.join(decrypted_dir, f"decrypted_{file_name}")
                            
                            try:
                                success = self.recovery.decrypt_file(
                                    file_path, 
                                    tool_id=tool_id, 
                                    output_file=output_file,
                                    options={'family': family}
                                )
                                
                                result = {
                                    'file': file_path,
                                    'tool': tool_id,
                                    'success': success,
                                    'output_file': output_file if success else None
                                }
                                
                                decryption_results.append(result)
                                
                                if success:
                                    logger.info(f"Successfully decrypted {file_path} with {tool_id}")
                                    # Update overall results
                                    self.results['decryption_successful'] = True
                                else:
                                    logger.info(f"Failed to decrypt {file_path} with {tool_id}")
                                    
                            except Exception as e:
                                logger.error(f"Error during decryption of {file_path}: {e}")
                                decryption_results.append({
                                    'file': file_path,
                                    'tool': tool_id,
                                    'success': False,
                                    'error': str(e)
                                })
            else:
                logger.warning(f"No decryption tools available for family: {family}")
                
                # Try auto mode with RansomwareRecovery
                logger.info("Attempting auto-decryption...")
                
                for file_path in files_to_decrypt:
                    if os.path.exists(file_path):
                        file_name = os.path.basename(file_path)
                        output_file = os.path.join(decrypted_dir, f"decrypted_{file_name}")
                        
                        try:
                            success = self.recovery.decrypt_file(
                                file_path, 
                                output_file=output_file,
                                options={'family': family}
                            )
                            
                            result = {
                                'file': file_path,
                                'tool': 'auto',
                                'success': success,
                                'output_file': output_file if success else None
                            }
                            
                            decryption_results.append(result)
                            
                            if success:
                                logger.info(f"Successfully auto-decrypted {file_path}")
                                # Update overall results
                                self.results['decryption_successful'] = True
                            else:
                                logger.info(f"Failed to auto-decrypt {file_path}")
                                
                        except Exception as e:
                            logger.error(f"Error during auto-decryption of {file_path}: {e}")
                            decryption_results.append({
                                'file': file_path,
                                'tool': 'auto',
                                'success': False,
                                'error': str(e)
                            })
        else:
            logger.warning("No ransomware family identified, attempting generic decryption...")
            
            # Try generic decryption techniques
            for file_path in files_to_decrypt:
                if os.path.exists(file_path):
                    file_name = os.path.basename(file_path)
                    output_file = os.path.join(decrypted_dir, f"decrypted_{file_name}")
                    
                    try:
                        success = self.recovery.decrypt_file(
                            file_path, 
                            output_file=output_file
                        )
                        
                        result = {
                            'file': file_path,
                            'tool': 'generic',
                            'success': success,
                            'output_file': output_file if success else None
                        }
                        
                        decryption_results.append(result)
                        
                        if success:
                            logger.info(f"Successfully decrypted {file_path} with generic approach")
                            # Update overall results
                            self.results['decryption_successful'] = True
                        else:
                            logger.info(f"Failed to decrypt {file_path} with generic approach")
                            
                    except Exception as e:
                        logger.error(f"Error during generic decryption of {file_path}: {e}")
                        decryption_results.append({
                            'file': file_path,
                            'tool': 'generic',
                            'success': False,
                            'error': str(e)
                        })
        
        # Save decryption results
        self.results['decryption_attempts'] = decryption_results
        
        # Write report to file
        decryption_report_path = os.path.join(self.output_dir, 'decryption', 'decryption_results.json')
        with open(decryption_report_path, 'w') as f:
            json.dump(decryption_results, f, indent=2)
        
        logger.info(f"Decryption report saved to: {decryption_report_path}")
        return decryption_results
    
    def generate_comprehensive_report(self):
        """Generate a comprehensive analysis report in markdown format"""
        logger.info("Generating comprehensive report...")
        
        # Create report file
        report_path = os.path.join(self.output_dir, 'reports', 'comprehensive_analysis.md')
        
        # Format results as markdown
        with open(report_path, 'w', encoding='utf-8') as f:
            # Title
            f.write(f"# vo����J\n\n")
            f.write(f"*��: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n\n")
            
            # Sample information
            f.write("## 7,�o\n\n")
            f.write(f"- **��**: {self.results['sample']['name']}\n")
            f.write(f"- **��'**: {self.results['sample']['size']} W�\n")
            f.write(f"- **��{�**: {self.results.get('static_analysis', {}).get('file_type', '*�')}\n")
            f.write(f"- **MD5**: `{self.results['sample']['hashes'].get('md5', '*�')}`\n")
            f.write(f"- **SHA1**: `{self.results['sample']['hashes'].get('sha1', '*�')}`\n")
            f.write(f"- **SHA256**: `{self.results['sample']['hashes'].get('sha256', '*�')}`\n\n")
            
            # Analysis summary
            f.write("## �X�\n\n")
            
            if self.results['identified_family']:
                f.write(f"**�K0��"o���**: {self.results['identified_family']} (n�: {self.results['family_confidence']:.2f})\n\n")
            else:
                f.write("***�K0y��"o���**\n\n")
            
            # Check for malicious indicators
            malicious_indicators = []
            
            # Check for ransomware indicators
            ransomware_indicators = self.results.get('static_analysis', {}).get('indicators', {}).get('ransomware', {})
            if ransomware_indicators:
                malicious_indicators.append(f"Ѱ�"o��sW&2: {', '.join(list(ransomware_indicators.keys())[:5])}")
            
            # Check for encryption indicators
            encryption_indicators = self.results.get('static_analysis', {}).get('indicators', {}).get('encryption', {})
            if encryption_indicators:
                malicious_indicators.append(f"Ѱ���sW&2: {', '.join(list(encryption_indicators.keys())[:5])}")
            
            # Check for category scores
            category_scores = self.results.get('static_analysis', {}).get('category_scores', {})
            if category_scores and category_scores.get('ransomware', 0) > 0.5:
                malicious_indicators.append(f"�"o�L:���: {category_scores.get('ransomware', 0):.2f}/1.0")
            
            # Check for high entropy sections
            high_entropy_sections = self.results.get('static_analysis', {}).get('high_entropy_sections', [])
            if high_entropy_sections:
                malicious_indicators.append(f"�K0 {len(high_entropy_sections)} *ص���(���S")
            
            # Check for network indicators
            network_indicators = self.results.get('network_analysis', {}).get('network_indicators', {})
            if network_indicators and (network_indicators.get('urls', []) or network_indicators.get('domains', [])):
                malicious_indicators.append(f"�K0�Q�: {len(network_indicators.get('urls', [])) + len(network_indicators.get('domains', []))} *URL/�")
            
            # Check for C2 patterns
            c2_patterns = self.results.get('network_analysis', {}).get('c2_pattern_matches', [])
            if c2_patterns:
                malicious_indicators.append(f"�K0 {len(c2_patterns)} *�"o�}�6(C2)�!")
            
            # Check for decryption attempts
            if self.results['decryption_successful']:
                malicious_indicators.append("��KՇ��L���")
            
            # Write malicious indicators
            f.write("### ;�Ѱ\n\n")
            if malicious_indicators:
                for indicator in malicious_indicators:
                    f.write(f"- {indicator}\n")
            else:
                f.write("- *Ѱ>�v\n")
            f.write("\n")
            
            # Static analysis details
            f.write("## Y�\n\n")
            
            # Write category scores
            f.write("### L:{�\n\n")
            if category_scores:
                f.write("| {+ | � |\n")
                f.write("|------|------|\n")
                for category, score in category_scores.items():
                    f.write(f"| {category} | {score:.2f} |\n")
            else:
                f.write("*�LL:{�\n")
            f.write("\n")
            
            # Write indicators by category
            f.write("### W&2\n\n")
            indicators = self.results.get('static_analysis', {}).get('indicators', {})
            if indicators:
                for category, matches in indicators.items():
                    if matches:
                        f.write(f"#### {category} {+\n\n")
                        f.write("|  | ��!p |\n")
                        f.write("|------|----------|\n")
                        for indicator, count in matches.items():
                            f.write(f"| {indicator} | {count} |\n")
                        f.write("\n")
            else:
                f.write("*Ѱy�\n\n")
            
            # PE file analysis if available
            pe_imports = self.results.get('static_analysis', {}).get('pe_imports', {})
            if pe_imports:
                f.write("### PE���e�\n\n")
                f.write("#### �e�DLL��p\n\n")
                
                # Filter to show only the most interesting imports
                interesting_dlls = [
                    'kernel32.dll', 'advapi32.dll', 'crypt32.dll', 'wininet.dll', 
                    'ws2_32.dll', 'user32.dll', 'urlmon.dll', 'shell32.dll'
                ]
                
                # Suspicious API functions to highlight
                suspicious_apis = [
                    'CryptEncrypt', 'CryptDecrypt', 'CreateProcess', 'VirtualAlloc',
                    'WriteProcessMemory', 'ReadProcessMemory', 'CreateRemoteThread',
                    'RegSetValue', 'InternetConnect', 'HttpSendRequest', 'socket'
                ]
                
                for dll_name, functions in pe_imports.items():
                    if dll_name.lower() in [d.lower() for d in interesting_dlls]:
                        f.write(f"**{dll_name}**:\n\n")
                        
                        # Highlight suspicious functions
                        marked_functions = []
                        for func in functions[:20]:  # Limit to first 20 functions
                            if any(sus.lower() in func.lower() for sus in suspicious_apis):
                                marked_functions.append(f"**{func}** =")
                            else:
                                marked_functions.append(func)
                        
                        f.write(", ".join(marked_functions))
                        if len(functions) > 20:
                            f.write(f", ... �� {len(functions) - 20} *v��p")
                        f.write("\n\n")
            
            # Network analysis details
            f.write("## Q��\n\n")
            
            # Write network indicators
            network_indicators = self.results.get('network_analysis', {}).get('network_indicators', {})
            if network_indicators:
                # URLs
                urls = network_indicators.get('urls', [])
                if urls:
                    f.write("### �K0�URL\n\n")
                    for url in urls[:10]:  # Limit to first 10
                        f.write(f"- `{url}`\n")
                    if len(urls) > 10:
                        f.write(f"- *�� {len(urls) - 10} *v�URL*\n")
                    f.write("\n")
                
                # Domains
                domains = network_indicators.get('domains', [])
                if domains:
                    f.write("### �K0��\n\n")
                    for domain in domains[:10]:  # Limit to first 10
                        f.write(f"- `{domain}`\n")
                    if len(domains) > 10:
                        f.write(f"- *�� {len(domains) - 10} *v��*\n")
                    f.write("\n")
                
                # IPs
                ips = network_indicators.get('ip_addresses', [])
                if ips:
                    f.write("### �K0�IP0@\n\n")
                    for ip in ips[:10]:  # Limit to first 10
                        f.write(f"- `{ip}`\n")
                    if len(ips) > 10:
                        f.write(f"- *�� {len(ips) - 10} *v�IP0@*\n")
                    f.write("\n")
            else:
                f.write("*�K0Q�\n\n")
            
            # C2 pattern matches
            c2_patterns = self.results.get('network_analysis', {}).get('c2_pattern_matches', [])
            if c2_patterns:
                f.write("### }�6(C2)�!\n\n")
                f.write("| �"o��� | 9M!p� | n� |\n")
                f.write("|--------------|------------|--------|\n")
                for c2 in c2_patterns:
                    f.write(f"| {c2['family']} | {c2['match_count']} | {c2['confidence']:.2f} |\n")
                f.write("\n")
                
                # Show detailed pattern matches for the best match
                best_match = max(c2_patterns, key=lambda x: x['confidence'])
                f.write(f"#### {best_match['family']} 9M��\n\n")
                f.write("| ! | n� |\n")
                f.write("|------|--------|\n")
                for pattern in best_match['pattern_matches'][:5]:  # Limit to first 5
                    f.write(f"| `{pattern['pattern']}` | {pattern['confidence']:.2f} |\n")
                if len(best_match['pattern_matches']) > 5:
                    f.write(f"| *�� {len(best_match['pattern_matches']) - 5} *v�!* | - |\n")
                f.write("\n")
            
            # Encryption capabilities
            f.write("## ���\n\n")
            
            encryption_analysis = self.results.get('static_analysis', {}).get('encryption_analysis', {})
            if encryption_analysis:
                # Check for identified encryption algorithm
                if 'encryption_details' in encryption_analysis and 'likely_algorithm' in encryption_analysis['encryption_details']:
                    algo = encryption_analysis['encryption_details']['likely_algorithm']
                    mode = encryption_analysis['encryption_details'].get('mode', 'unknown')
                    confidence = encryption_analysis['encryption_details'].get('confidence', 0)
                    f.write(f"**�K0��Ɨ�**: {algo} {mode} (n�: {confidence:.2f})\n\n")
                    
                # Check for identified family
                if 'potential_family' in encryption_analysis:
                    family = encryption_analysis['potential_family']
                    family_confidence = encryption_analysis.get('family_confidence', 0)
                    f.write(f"**\(�"o���**: {family} (n�: {family_confidence:.2f})\n\n")
                    
                # Assessment
                if 'assessment' in encryption_analysis:
                    f.write(f"**�0**: {encryption_analysis['assessment']}\n\n")
                    
                # Decryption possibilities
                if 'decryption_possibilities' in encryption_analysis:
                    decr = encryption_analysis['decryption_possibilities']
                    f.write("### ����'\n\n")
                    f.write(f"- **�0**: {decr.get('assessment', '*�')}\n")
                    f.write(f"- **��**: {decr.get('method', '*�')}\n")
                    f.write(f"- **���**: {decr.get('probability', '*�')}\n")
                    f.write(f"- **/&	M9���w**: {'/' if decr.get('free_decryptor_available', False) else '&'}\n\n")
                    
                # Available tools
                if 'available_tools' in encryption_analysis and encryption_analysis['available_tools']:
                    f.write("### �(���w\n\n")
                    for tool in encryption_analysis['available_tools']:
                        status = "��" if tool.get('installed', False) else "�(F*��"
                        f.write(f"- **{tool['name']}** ({tool['id']}): {status}\n")
                        if 'description' in tool:
                            f.write(f"  - {tool['description']}\n")
                        if 'url' in tool and tool['url']:
                            f.write(f"  - URL: {tool['url']}\n")
                    f.write("\n")
            else:
                f.write("*gL���*Ѱ�Ɵ�\n\n")
            
            # Decryption attempts
            f.write("## ���\n\n")
            
            decryption_attempts = self.results['decryption_attempts']
            if decryption_attempts:
                # Count successful and failed attempts
                successful = sum(1 for attempt in decryption_attempts if attempt['success'])
                failed = len(decryption_attempts) - successful
                
                f.write(f"q��� {len(decryption_attempts)} !{successful} !�{failed} !1%\n\n")
                
                if successful > 0:
                    f.write("### �����\n\n")
                    f.write("| �� | (��w | ���� |\n")
                    f.write("|------|-----------|----------|\n")
                    for attempt in decryption_attempts:
                        if attempt['success']:
                            file_name = os.path.basename(attempt['file'])
                            output_name = os.path.basename(attempt['output_file']) if attempt['output_file'] else 'N/A'
                            f.write(f"| {file_name} | {attempt['tool']} | {output_name} |\n")
                    f.write("\n")
                
                if failed > 0:
                    f.write("### 1%����\n\n")
                    f.write("| �� | (��w | 1%�� |\n")
                    f.write("|------|-----------|----------|\n")
                    for attempt in decryption_attempts:
                        if not attempt['success']:
                            file_name = os.path.basename(attempt['file'])
                            error = attempt.get('error', '*�')
                            f.write(f"| {file_name} | {attempt['tool']} | {error} |\n")
                    f.write("\n")
            else:
                f.write("*gL���\n\n")
            
            # Conclusion and recommendations
            f.write("## Ӻ��\n\n")
            
            # Generate conclusion based on analysis results
            if self.results['identified_family']:
                family = self.results['identified_family']
                f.write(f"7,��+: **{family}** �"o�n�: {self.results['family_confidence']:.2f}")
                
                # Add decryption status
                if self.results['decryption_successful']:
                    f.write(" (�	�w��ƆKՇ��h�ӄpn��/�b�\n\n")
                else:
                    f.write(" *����KՇ��h���"o���ƹH�::'����bpn\n\n")
                
                # Add specific family info
                encryption_analysis = self.results.get('static_analysis', {}).get('encryption_analysis', {})
                if 'decryption_possibilities' in encryption_analysis:
                    decr = encryption_analysis['decryption_possibilities']
                    f.write(f"{decr.get('assessment', '')}\n\n")
            else:
                # Generic conclusion based on indicators
                category_scores = self.results.get('static_analysis', {}).get('category_scores', {})
                if category_scores and category_scores.get('ransomware', 0) > 0.5:
                    f.write("}6*�n�wS��"o���F�7,>:�>��"o�y�")
                    if self.results['decryption_successful']:
                        f.write(" =��d((����ƆKՇ��h�ӄpn��/�b�\n\n")
                    else:
                        f.write(" *����KՇ��h���"o�(�:�ƹH����bpn\n\n")
                else:
                    f.write("�7,*>:n��"o�y����/v�{��vo�/ **���+����"o���\n\n")
            
            # Recommendations
            f.write("### ��\n\n")
            
            # Standard recommendations
            recommendations = [
                "�/�N�d^��Ł�v�	�",
                "�� https://www.nomoreransom.org ��M9����w",
                "S0g�:���sQ܉h:��J��",
                "�����(�L:���ƥ��U��Xl�",
                "��Ƈ���o,",
                "���ӄ���2b� e �"
            ]
            
            # Add specific recommendations based on analysis
            if self.results['identified_family']:
                family = self.results['identified_family']
                
                # Add family-specific recommendations
                if family == "WannaCry":
                    recommendations.insert(0, "(WanaKiwi/WannaKey�w�΅X-��ƥ����*�/	")
                elif family == "STOP" or family == "Djvu":
                    recommendations.insert(0, "(Emsisoft STOP Decryptor(�ƥpn����")
                elif family == "LockBit":
                    recommendations.insert(0, "��/&	 ��LockBit���w ����hv�X4�")
            
            # Write recommendations
            for recommendation in recommendations:
                f.write(f"- {recommendation}\n")
            f.write("\n")
            
            # Disclaimer
            f.write("## M#�\n\n")
            f.write(",����!�+��/100%�n��s.ŵ��Ȩ�Q܉h�X\n")
        
        logger.info(f"Comprehensive report saved to: {report_path}")
        return report_path
    
    def run(self):
        """Execute the complete analysis workflow"""
        try:
            # 1. Compute hashes
            if not self.compute_hashes():
                return False
            
            # 2. Prepare sample
            if not self.prepare_sample():
                return False
            
            # 3. Perform static analysis
            if not self.perform_static_analysis():
                logger.warning("Static analysis failed or partially failed")
            
            # 4. Extract network indicators
            if not self.extract_network_indicators():
                logger.warning("Network analysis failed or partially failed")
            
            # 5. Prepare for dynamic analysis
            if not self.prepare_dynamic_analysis():
                logger.warning("Dynamic analysis preparation failed or partially failed")
            
            # 6. Attempt decryption
            self.attempt_decryption()
            
            # 7. Generate comprehensive report
            self.generate_comprehensive_report()
            
            logger.info(f"Analysis completed. Results saved to: {self.output_dir}")
            return True
        
        except Exception as e:
            logger.error(f"Error during analysis: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
        

def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description="Advanced Malware Analysis")
    parser.add_argument("sample", help="Path to malware sample")
    parser.add_argument("-o", "--output-dir", help="Output directory")
    parser.add_argument("-w", "--work-dir", help="Working directory")
    parser.add_argument("-v", "--verbose", action="store_true", help="Enable verbose logging")
    
    args = parser.parse_args()
    
    analyzer = AdvancedMalwareAnalyzer(
        sample_path=args.sample,
        output_dir=args.output_dir,
        work_dir=args.work_dir,
        verbose=args.verbose
    )
    
    success = analyzer.run()
    
    if success:
        print(f"Analysis completed successfully. Results saved to: {analyzer.output_dir}")
        print(f"Comprehensive report: {os.path.join(analyzer.output_dir, 'reports', 'comprehensive_analysis.md')}")
        return 0
    else:
        print("Analysis failed. Check logs for details.")
        return 1


if __name__ == "__main__":
    sys.exit(main())